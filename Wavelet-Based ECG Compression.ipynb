{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import various libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from pywt import wavedec\n",
    "import pywt\n",
    "import numpy as np\n",
    "from scipy.signal import lfilter\n",
    "import pandas as pd\n",
    "import scipy.signal as signal\n",
    "from scipy.stats import iqr\n",
    "import sys\n",
    "import copy\n",
    "\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIR filter coefficients for HPF and LPF generated using matlab. These are equiripple filters with cutoff frequencies of 3/5Hz and 38/42Hz respectively. Both are of order 30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate FIR filter coeffs using matlab\n",
    "filters = {}\n",
    "filters['b_hpf_5hz'] = [-0.197867802488742, -0.0223111834022511, -0.0233980992556299, -0.0245591620459658, -0.0255409709438292, -0.0264980119455013, -0.0273219663603278, -0.0282661633639305, -0.0290666320999297, -0.0295497279590883, -0.0301521603512992, -0.0306588019952879, -0.0309578031663793, -0.0312049403207207, -0.03134442914648, 0.968527520520961, -0.03134442914648, -0.0312049403207207, -0.0309578031663793, -0.0306588019952879, -0.0301521603512992, -0.0295497279590883, -0.0290666320999297, -0.0282661633639305, -0.0273219663603278, -0.0264980119455013, -0.0255409709438292, -0.0245591620459658, -0.0233980992556299, -0.0223111834022511, -0.197867802488742]\n",
    "filters['b_lpf_40hz'] = [0.0468130734890904, 0.146455226396587, -0.0317230935630268, -0.00916483236202123, -0.0333859647512817, -0.0117562031113877, 0.0200686108179674, 0.0409236312368036, 0.0257162788640763, -0.0205874893332207, -0.063048991609236, -0.0566820018428517, 0.0207298678589156, 0.147289624014856, 0.264830218893494, 0.312523688522207, 0.264830218893494, 0.147289624014856, 0.0207298678589156, -0.0566820018428517, -0.063048991609236, -0.0205874893332207, 0.0257162788640763, 0.0409236312368036, 0.0200686108179674, -0.0117562031113877, -0.0333859647512817, -0.00916483236202123, -0.0317230935630268, 0.146455226396587, 0.0468130734890904]\n",
    "\n",
    "NUM_BITS_DATA = 12       #define the number of bits in the original data is stored as\n",
    "FS = 100                 #define the sampling rate\n",
    "NUM_SAMPLES_BLOCK = 1000 #define the number of samples of data to compress in each block\n",
    "\n",
    "#don't allow the PRD to be greater than 5%\n",
    "MAX_PRD = 0.05\n",
    "\n",
    "#enable/disable plotting\n",
    "do_plot = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to do wavelet decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wavelet_decomposition(sig):\n",
    "    cA2, cD2, cD1 = wavedec(sig, 'db4', level=2)\n",
    "    coeffs = {'cA2': cA2, 'cD2': cD2, 'cD1': cD1}\n",
    "\n",
    "    return coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to do wavelet reconstruction given the approximation and detail coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wavelet_reconstruction(coeffs):\n",
    "    reconstructed = pywt.waverec([coeffs['cA2'], coeffs['cD2'], coeffs['cD1']], 'db4')\n",
    "\n",
    "    return reconstructed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to scale wavelet coefficients to +/- 1. This makes the quantization step consistent regardless of scaling. Return the scaling factors to re-scale to the original range later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scale_coeffs(coeffs):\n",
    "    coeffs_scaled = {}\n",
    "    scaling_factors = {}\n",
    "\n",
    "    for key in coeffs.keys():\n",
    "        tmp_scaling_factor = np.max(np.abs(coeffs[key]))\n",
    "        tmp_scaled_coeffs = coeffs[key]/tmp_scaling_factor\n",
    "\n",
    "        scaling_factors[key] = tmp_scaling_factor\n",
    "        coeffs_scaled[key] = tmp_scaled_coeffs\n",
    "\n",
    "    return coeffs_scaled, scaling_factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to unscale the wavelet coefficients, given the scaling factor and number of bits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unscale_coeffs(coeffs, scaling_factors, bits):\n",
    "    coeffs_unscaled = {}\n",
    "\n",
    "    for key in coeffs.keys():\n",
    "        tmp_coeffs_unscaled = coeffs[key]*scaling_factors[key]/(2**(bits-1))\n",
    "\n",
    "        coeffs_unscaled[key] = tmp_coeffs_unscaled\n",
    "\n",
    "    return coeffs_unscaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to combine all the different wavelet coefficients into a single array. This is to simplify the compression step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_coefficients(coeffs):\n",
    "    coeffs_combined = []\n",
    "\n",
    "    #add in each array to coeffs_combined\n",
    "    coeffs_combined.extend(coeffs['cA2'])\n",
    "    coeffs_combined.extend(coeffs['cD2'])\n",
    "    coeffs_combined.extend(coeffs['cD1'])\n",
    "\n",
    "    #create a mapping of where there are values of zero or nonzero\n",
    "    #this is the \"binary map\"\n",
    "    coeffs_combined = np.array(coeffs_combined)\n",
    "    binary_map = copy.deepcopy(coeffs_combined)\n",
    "    binary_map[np.where(binary_map!=0)[0]] = 1\n",
    "\n",
    "    #drop zero indices\n",
    "    zero_inds = np.where(coeffs_combined==0)[0]\n",
    "    coeffs_combined = np.delete(coeffs_combined, zero_inds)\n",
    "\n",
    "    return coeffs_combined, binary_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to re-map the array of wavelet coefficients back to the original format with zeros, based on the binary map. Also put them back into their respective wavelet decompositions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remap_coeffs(coeffs, binary_map, coeff_lengths):\n",
    "    coeffs_remapped = np.zeros(len(binary_map))\n",
    "    coeffs_remapped[binary_map==1] = coeffs\n",
    "\n",
    "    wavelet_remapped = {}\n",
    "    wavelet_remapped['cA2'] = coeffs_remapped[0:coeff_lengths['cA2']]\n",
    "    wavelet_remapped['cD2'] = coeffs_remapped[coeff_lengths['cA2']:coeff_lengths['cA2']+coeff_lengths['cD2']]\n",
    "    wavelet_remapped['cD1'] = coeffs_remapped[coeff_lengths['cA2']+coeff_lengths['cD2']:]\n",
    "\n",
    "    return wavelet_remapped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to convert the quantized coefficients (which are integers, max 8 bit signed) to ascii characters for LZW compression. If it's a signed number, shift up by num_bits to ensure it's positive because ascii values only correspond to positive integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def int_to_ascii(array, num_bits=None):\n",
    "    ascii_str = ''\n",
    "\n",
    "    #loop through each integer in the array\n",
    "    for val in array:\n",
    "        if num_bits is not None:\n",
    "            #add by 2^(num_bits-1) to make sure all the values are positive\n",
    "            val = val + 2**(num_bits-1)\n",
    "\n",
    "        #append the character to the string\n",
    "        ascii_str = ascii_str + chr(val)\n",
    "\n",
    "    return ascii_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to convert an ascii string back to an int array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ascii_to_int(string, num_bits=None):\n",
    "\n",
    "    if num_bits is None:\n",
    "        arr = [ord(c) for c in string]\n",
    "    else:\n",
    "        arr = [ord(c)-2**(num_bits-1) for c in string]\n",
    "\n",
    "    return np.array(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to compress a string to a list of output symbols using the LZW algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compress(string):\n",
    "    #use the extended ascii table\n",
    "    dict_size = 256\n",
    "\n",
    "    #build the dictionary\n",
    "    dictionary = {}\n",
    "    for i in range(dict_size):\n",
    "        dictionary[chr(i)] = i\n",
    "\n",
    "    result = []\n",
    "\n",
    "    #loop through each character in the string and handle accordingly\n",
    "    w = \"\"\n",
    "    for c in string:\n",
    "        wc = w + c\n",
    "        if wc in dictionary:\n",
    "            w = wc\n",
    "        else:\n",
    "            result.append(dictionary[w])\n",
    "            # add wc to the dictionary\n",
    "            dictionary[wc] = dict_size\n",
    "            dict_size += 1\n",
    "            w = c\n",
    "\n",
    "    # output the code for w\n",
    "    if w:\n",
    "        result.append(dictionary[w])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to decompress a list of output symbols to a string using the LZW algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decompress(compressed):\n",
    "    #use the extended ascii table\n",
    "    dict_size = 256\n",
    "\n",
    "    #build the dictionary\n",
    "    dictionary = {}\n",
    "    for i in range(dict_size):\n",
    "        dictionary[i] = chr(i)\n",
    "\n",
    "    w = chr(compressed.pop(0))\n",
    "    result = [w]\n",
    "\n",
    "    for k in compressed:\n",
    "        if k in dictionary:\n",
    "            entry = dictionary[k]\n",
    "        elif k == len(dictionary):\n",
    "            entry = w + w[0]\n",
    "        else:\n",
    "            print(\"Bad compressed\")\n",
    "\n",
    "        result.append(entry)\n",
    "\n",
    "        dictionary[dict_size] = w + entry[0]\n",
    "        dict_size += 1\n",
    "\n",
    "        w = entry\n",
    "\n",
    "    result = ''.join(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to calculate the final compression ratio between the input data and the LZW compressed array. The number of bits in the input signal is calculated as the number of samples times the number of bits per sample. The number of bits in the compressed signal is calculated as the sum of the number of bits of each number in the compressed coefficients and the compressed binary map. Also, each of the scaling coefficients are added as 32 bit floating point numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_compression_ratio(coeffs_compressed, binary_map_compressed, num_scaling_factors):\n",
    "    num_bits_compressed = 0\n",
    "\n",
    "    #loop through each value in the compressed coefficients and compressed binary map\n",
    "    #and count the number of bits each number uses\n",
    "    for val in coeffs_compressed:\n",
    "        num_bits_compressed = num_bits_compressed + len('{0:b}'.format(val))\n",
    "\n",
    "    for val in binary_map_compressed:\n",
    "        num_bits_compressed = num_bits_compressed + len('{0:b}'.format(val))\n",
    "\n",
    "    #assuming floating point values are 32 bits\n",
    "    num_bits_compressed = num_bits_compressed + 32*num_scaling_factors\n",
    "\n",
    "    #get the number of bits in the original data\n",
    "    num_bits_uncompressed = NUM_BITS_DATA*NUM_SAMPLES_BLOCK\n",
    "\n",
    "    #get the compression ratio\n",
    "    compression_ratio = num_bits_uncompressed/num_bits_compressed\n",
    "\n",
    "    return compression_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to quantize wavelet coefficients to an integer with a defined number of bits. This is assuming the coefficients have already been scaled to +/- 1. The highest number of bits is 8, and the lowest number of bits is 2. To determine the appropriate nubmer of bits to quanitize the signal, start at 8 bits and then do wavelet reconstruction. Then calculate the percent root mean square difference (PRD) between the reconstructed and original, and keep quantizing with less bits until the PRD is below the MAX_PRD threshold (currently set to 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def quantize(orig_sig, scaled_coeffs, scaling_factors):\n",
    "    #starting at 8 bits, keep decreasing the number of bits in the quantization\n",
    "    #until the PRD is above some threshold. minimum number of bits is 2 since it's\n",
    "    #a signed integer\n",
    "    bits = 9\n",
    "\n",
    "    #initialize PRD to 0 so the while loop can run\n",
    "    PRD = 0\n",
    "\n",
    "    if do_plot:\n",
    "        plt.subplots(figsize=(16,9))\n",
    "        t = [i*1/FS for i in range(NUM_SAMPLES_BLOCK)]\n",
    "\n",
    "    while (bits > 1) and (PRD <= MAX_PRD):\n",
    "        #decrement the number of bits\n",
    "        bits = bits-1\n",
    "\n",
    "        #get quantized coefficients\n",
    "        quantized_coeffs = do_quantization(scaled_coeffs, bits)\n",
    "\n",
    "        #unscale the data back to the original scale\n",
    "        unscaled_coeffs = unscale_coeffs(quantized_coeffs, scaling_factors, bits)\n",
    "\n",
    "        #do wavelet reconstruction on the quantized, unscaled coefficients\n",
    "        reconstructed_sig = wavelet_reconstruction(unscaled_coeffs)\n",
    "\n",
    "        #plot stuff\n",
    "        if do_plot and bits >= 4:\n",
    "            plt.plot(t, reconstructed_sig, label='Reconstructed @ %i Bits' % bits)\n",
    "\n",
    "        #calculate PRD\n",
    "        PRD = calculate_PRD(orig_sig, reconstructed_sig)\n",
    "\n",
    "    #go back to the previous quantization level if the PRD threshold was crossed\n",
    "    if PRD > MAX_PRD:\n",
    "        bits = bits+1\n",
    "        quantized_coeffs = do_quantization(scaled_coeffs, bits)\n",
    "        unscaled_coeffs = unscale_coeffs(quantized_coeffs, scaling_factors, bits)\n",
    "        reconstructed_sig = wavelet_reconstruction(unscaled_coeffs)\n",
    "        PRD = calculate_PRD(orig_sig, reconstructed_sig)\n",
    "\n",
    "    #plot some more stuff\n",
    "    if do_plot:\n",
    "        plt.plot(t, orig_sig, label='Original Signal')\n",
    "        plt.title('PRD @ %i Bits = %f' % (bits, PRD))\n",
    "        plt.legend(loc=1)\n",
    "        plt.tight_layout()\n",
    "        plt.xlabel('Time (seconds)')\n",
    "        plt.ylabel('Amplitude (mV)')\n",
    "        plt.savefig('figs/PRD.png', dpi=150)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    return quantized_coeffs, bits, PRD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to do quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_quantization(coeffs, bits):\n",
    "    quantized_coeffs = {}\n",
    "\n",
    "    for key in coeffs.keys():\n",
    "        #multiply by 2^(bits-1) because its a signed number\n",
    "        sig = coeffs[key]\n",
    "        sig = sig*(2**(bits-1))\n",
    "        sig = np.round(sig)\n",
    "        sig = np.array(sig).astype(int)\n",
    "\n",
    "        quantized_coeffs[key] = sig\n",
    "\n",
    "    return quantized_coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to calcluate the PRD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_PRD(orig_sig, reconstructed_sig):\n",
    "    num = np.sum((orig_sig - reconstructed_sig)**2)\n",
    "    den = np.sum(orig_sig**2)\n",
    "\n",
    "    PRD = num/den\n",
    "\n",
    "    return PRD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main section of the code that loads up data from a pandas dataframe, loops over data in 10 second chunks, performs compression, and then performs decompression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nbobra/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average compression ratio: 5.633\n",
      "Average PRD: 0.025\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "df = pd.read_pickle('apnea_ecg.pkl')\n",
    "\n",
    "#calculate the number of 10 second non-overlapping blocks of data\n",
    "N = int(len(df)/NUM_SAMPLES_BLOCK)\n",
    "\n",
    "#calculate the average CR and average PRD\n",
    "CR_avg = 0\n",
    "PRD_avg = 0\n",
    "\n",
    "#loop over the data in 10 second chunks\n",
    "for i in range(N):\n",
    "    data = df.ix[i*NUM_SAMPLES_BLOCK:(i+1)*NUM_SAMPLES_BLOCK-1, 0].values\n",
    "\n",
    "    #subtract out the mean as a precprocessing step\n",
    "    #for comparison purposes, the mean can be added in after reconstruction\n",
    "    data = data - np.mean(data)\n",
    "\n",
    "    #do wavelet decomposition \n",
    "    coeffs = wavelet_decomposition(data)\n",
    "\n",
    "    #scale each set of wavelet coefficients to +/- 1 \n",
    "    #keep track of the scaling factors to re-scale to the original range later\n",
    "    coeffs_scaled, scaling_factors = scale_coeffs(coeffs)\n",
    "\n",
    "    #do quantization\n",
    "    coeffs_quantized, num_bits, PRD = quantize(data, coeffs_scaled, scaling_factors)\n",
    "    PRD_avg = PRD_avg + PRD\n",
    "\n",
    "    #now combine all the coefficients into a single array\n",
    "    coeffs_combined, binary_map = combine_coefficients(coeffs_quantized)\n",
    "\n",
    "    #convert the quantized coefficients (which are integers, max 8 bit signed)\n",
    "    #to ascii characters for LZW compression\n",
    "    coeffs_ascii = int_to_ascii(coeffs_combined, num_bits)\n",
    "    binary_map_ascii = int_to_ascii(binary_map)\n",
    "\n",
    "    #compress and \"transmit\" the wavelet coefficients and the binary map\n",
    "    coeffs_compressed = compress(coeffs_ascii)\n",
    "    binary_map_compressed = compress(binary_map_ascii)\n",
    "\n",
    "    #calculate the compression ratio\n",
    "    compression_ratio = calculate_compression_ratio(coeffs_compressed, binary_map_compressed, len(scaling_factors))\n",
    "    CR_avg = CR_avg + compression_ratio\n",
    "\n",
    "    #\"receive\" and uncompress the data\n",
    "    coeffs_decompressed = decompress(coeffs_compressed)\n",
    "    binary_map_decompressed = decompress(binary_map_compressed)\n",
    "\n",
    "    #convert ascii back to int\n",
    "    coeffs_int = ascii_to_int(coeffs_decompressed, num_bits)\n",
    "    binary_map_int = ascii_to_int(binary_map_decompressed)\n",
    "\n",
    "    #re-map the coefficients to the original format with zeros, based on the binary map\n",
    "    #also put them back into their respective wavelet decompositions\n",
    "    #before doing the remapping, find out the length of each wavelet approximation and detail coefficients\n",
    "    #this step isn't necessary if the length of the input signal is fixed\n",
    "    coeff_lengths = {'cA2': len(coeffs['cA2']), 'cD2': len(coeffs['cD2']), 'cD1': len(coeffs['cD1'])}\n",
    "    coeffs_remapped = remap_coeffs(coeffs_int, binary_map_int, coeff_lengths)\n",
    "\n",
    "    #unscale the coefficients\n",
    "    coeffs_unscaled = unscale_coeffs(coeffs_remapped, scaling_factors, num_bits)\n",
    "\n",
    "    #do wavelet reconstruction\n",
    "    data_reconstructed = wavelet_reconstruction(coeffs_unscaled)\n",
    "\n",
    "    if do_plot:\n",
    "        t = [i*1/FS for i in range(NUM_SAMPLES_BLOCK)]\n",
    "        plt.subplots(figsize=(16,9))\n",
    "        plt.plot(t, data, label='Original Signal')\n",
    "        plt.plot(t, data_reconstructed, label='Reconstructed Signal')\n",
    "        plt.title('Compression Ratio: %.1f' % compression_ratio)\n",
    "        plt.xlabel('Time (seconds)')\n",
    "        plt.ylabel('Amplitude (mV)')\n",
    "        plt.tight_layout()\n",
    "        plt.legend(loc=1)\n",
    "        plt.savefig('figs/reconstructed.png', dpi=150)\n",
    "        plt.show()\n",
    "\n",
    "#calculate the average compression ratio and PRD\n",
    "CR_avg = CR_avg/N\n",
    "PRD_avg = PRD_avg/N\n",
    "print('Average compression ratio: %.3f' % CR_avg)\n",
    "print('Average PRD: %.3f' % PRD_avg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
